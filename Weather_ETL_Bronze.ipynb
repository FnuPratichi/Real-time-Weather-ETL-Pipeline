{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b7895e5-8165-4835-a1a4-b2164d791032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**_Purpose: Extract from API → add timestamp → store raw JSON/hourly data as Delta._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2065d2f-3e5f-4d25-8185-1186499b3538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['latitude', 'longitude', 'generationtime_ms', 'utc_offset_seconds', 'timezone', 'timezone_abbreviation', 'elevation', 'hourly_units', 'hourly', 'extracted_at'])\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "url = \"https://api.open-meteo.com/v1/forecast?latitude=38.8951&longitude=-77.0364&hourly=temperature_2m,relative_humidity_2m,precipitation&timezone=America/New_York\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Add extraction timestamp\n",
    "data['extracted_at'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(data.keys())  # Should show 'latitude', 'longitude', 'hourly', etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b649e3c-aa63-4a86-bd2f-38826ce1ecb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>relative_humidity_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>extracted_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-22T00:00</td>\n",
       "      <td>19.5</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-09-22 19:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-22T01:00</td>\n",
       "      <td>19.2</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-09-22 19:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-22T02:00</td>\n",
       "      <td>18.5</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-09-22 19:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-22T03:00</td>\n",
       "      <td>18.3</td>\n",
       "      <td>78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-09-22 19:55:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-22T04:00</td>\n",
       "      <td>16.8</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-09-22 19:55:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time  temperature_2m  ...  precipitation         extracted_at\n",
       "0  2025-09-22T00:00            19.5  ...            0.0  2025-09-22 19:55:31\n",
       "1  2025-09-22T01:00            19.2  ...            0.0  2025-09-22 19:55:31\n",
       "2  2025-09-22T02:00            18.5  ...            0.0  2025-09-22 19:55:31\n",
       "3  2025-09-22T03:00            18.3  ...            0.0  2025-09-22 19:55:31\n",
       "4  2025-09-22T04:00            16.8  ...            0.0  2025-09-22 19:55:31\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "hourly_data = data['hourly']\n",
    "df = pd.DataFrame(hourly_data)\n",
    "df['extracted_at'] = data['extracted_at']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99754f0a-714c-4566-9bad-3d26d3caa53f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Step 3: Convert Pandas DataFrame to Spark DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8345441b-3d0d-4053-9fba-f438aa86cd2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert pandas DF to Spark DF\n",
    "bronze_spark_df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90244a91-c37d-44c2-9b92-cc951ec7d826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add a unique ID column to prevent duplicates\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "bronze_spark_df = bronze_spark_df.withColumn(\"id\", monotonically_increasing_id())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe7b32f6-831e-4cfb-af20-a64605aab053",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-------------+-------------------+----+\n|            time|temperature_2m|relative_humidity_2m|precipitation|       extracted_at|  id|\n+----------------+--------------+--------------------+-------------+-------------------+----+\n|2025-09-22T00:00|          19.5|                  73|          0.0|2025-09-22 19:39:01|NULL|\n|2025-09-22T01:00|          19.2|                  76|          0.0|2025-09-22 19:39:01|NULL|\n|2025-09-22T02:00|          18.5|                  80|          0.0|2025-09-22 19:39:01|NULL|\n|2025-09-22T03:00|          18.3|                  78|          0.0|2025-09-22 19:39:01|NULL|\n|2025-09-22T04:00|          16.8|                  84|          0.0|2025-09-22 19:39:01|NULL|\n+----------------+--------------+--------------------+-------------+-------------------+----+\n\n"
     ]
    }
   ],
   "source": [
    "# Save Spark DataFrame as Delta table\n",
    "\n",
    "# Save Spark DataFrame as Delta table with schema merge\n",
    "bronze_spark_df.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"weather_bronze\")\n",
    "\n",
    "# Quick check\n",
    "spark.sql(\"SELECT * FROM weather_bronze LIMIT 5\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Weather_ETL_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}